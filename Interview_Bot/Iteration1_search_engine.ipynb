{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search engine on unsupervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`This model can be used to answer by querying to make qa pair datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ## Any pdf file, Here Attention is all you need research paper was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(path)\n",
    "text  = ''\n",
    "for pages in reader.pages:\n",
    "    text += pages.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39472"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(raw_string):\n",
    "    #raw_string = raw_string.lower()\n",
    "    text = re.sub(r'[^A-Za-z]+',' ',raw_string) # remove punctuations\n",
    "    text = re.sub('\\s+',' ',text)                   # remove whitespaces\n",
    "\n",
    "    return text\n",
    "\n",
    "clean_text = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parma',\n",
       " 'r∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗ †\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe ',\n",
       " 'dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\n',\n",
       " 'based solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT',\n",
       " ' 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a smal']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = []\n",
    "\n",
    "chunk_size = 300\n",
    "\n",
    "for i in range(0, len(clean_text), chunk_size):\n",
    "    chunk = text[i:i+chunk_size]\n",
    "    chunks.append(chunk)\n",
    "chunks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.encode(sentences=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ST_search(corpus:list,query:str):\n",
    "    corpus_embeddings = model.encode(corpus)\n",
    "    query_embeddings = model.encode(query)\n",
    "    similarity = util.cos_sim(corpus_embeddings,query_embeddings)\n",
    "    \n",
    "    index = torch.argmax(similarity)\n",
    "    \n",
    "    result_text = ''\n",
    "    for i in range(index-1,index+1):\n",
    "        result_text += corpus[i]\n",
    "    print(f'Cosine Similarity = {similarity.max()}\\n\\nResult: {result_text}')\n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is positional Encodings?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity = 0.6015917658805847\n",
      "\n",
      "Result:  O(n)\n",
      "Convolutional O(k·n·d2) O(1) O(logk(n))\n",
      "Self-Attention (restricted) O(r·n·d) O(1) O(n/r)\n",
      "3.5 Positional Encoding\n",
      "Since our model contains no recurrence and no convolution, in order for the model to make use of the\n",
      "order of the sequence, we must inject some information about the relative or absolute position of the\n",
      "tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\n",
      "bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\n",
      "as the embeddings, so that the two can be summed. There are many choices of posit\n"
     ]
    }
   ],
   "source": [
    "result_text = ST_search(chunks,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "tokenized_corpus = [i.split(' ') for i in chunks]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "query='What is Positional Encoding?'\n",
    "doc_scores = bm25.get_scores(query.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = bm25.get_top_n(query.split(' '), chunks, n = 5)\n",
    "user_index = chunks.index(query_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(49,51):\n",
    "    result_text += chunks[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' O(n)\\nConvolutional O(k·n·d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r·n·d) O(1) O(n/r)\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positayer types. nis the sequence length, dis the representation dimension, kis the kernel\\nsize of convolutions and rthe size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2·d) O(1) O(1)\\nRecurrent O(n·d2) O(n) O(n)\\nConvolutional O(k·n·d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r·n·d) O(1) O(n/r)\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or abs'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_score : 0.603451936669993\n",
      "\n",
      "Answer : ayer types. nis the sequence length, dis the representation dimension, kis the kernel\n",
      "size of convolutions and rthe size of the neighborhood in restricted self-attention.\n",
      "Layer Type Complexity per Layer Sequential Maximum Path Length\n",
      "Operations\n",
      "Self-Attention O(n2·d) O(1) O(1)\n",
      "Recurrent O(n·d2) O(n) O(n)\n",
      "Convolutional O(k·n·d2) O(1) O(logk(n))\n",
      "Self-Attention (restricted) O(r·n·d) O(1) O(n/r)\n",
      "3.5 Positional Encoding\n",
      "Since our model contains no recurrence and no convolution, in order for the model to make use of the\n",
      "order of the sequence, we must inject some information about the relative or abs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bm25_search(corpus:list,query:str):\n",
    "    tokenized_corpus = [i.split(' ') for i in chunks]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    doc_scores = bm25.get_scores(query.split(' '))\n",
    "    user_index = chunks.index(query_results[0])\n",
    "    \n",
    "    # See below for reason of normalising\n",
    "    i = np.argsort(doc_scores)  # indicies of sorted array in ascending order\n",
    "    sorted_arr = doc_scores[i]  # Sorted array\n",
    "    sorted_arr = sorted_arr[-10:]\n",
    "    sorted_arr /= np.linalg.norm(sorted_arr)\n",
    "    user_score = max(sorted_arr)\n",
    "    \n",
    "    result_text = ''\n",
    "    for i in range(user_index-1,user_index+1):\n",
    "        result_text += corpus[i]\n",
    "    \n",
    "    return user_score, result_text\n",
    "\n",
    "user_score, result_text = bm25_search(chunks,query)\n",
    "print(f'User_score : {user_score}\\n\\nAnswer : {result_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
